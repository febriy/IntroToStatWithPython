{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "### Introduction: Motivation for DT\n",
    "- Simple and effective model for classification and regression problem.\n",
    "- Easy to understand, mimic human decision making.\n",
    "- Foundation to more advanced ensemble methods e.g. bagging, random forests, gradient boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does it look like?\n",
    "- Represented by a binary tree \n",
    " - each node can have 0,1,2 child nodes\n",
    " - A node represent a split point on that variable\n",
    " - The leaf/ terminal nodes are used to make prediction\n",
    " - Once created, we can imagine new data to be predicted traversing throughout the tree through the branches to the leaf node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Yaktocat](https://upload.wikimedia.org/wikipedia/commons/4/46/ID3_algorithm_decision_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create the tree?\n",
    "- Simply said, it is a process of dividing up the input space\n",
    "- Recursive binary splitting - a greedy approach used to divide the space. How does it work?\n",
    " - Line up all values \n",
    " - Try different split points\n",
    " - Test using a cost function\n",
    " - Choose the split with the lowest cost\n",
    "   - __Regression__ : sum squared error\n",
    "   - __Classification__ : Gini cost\n",
    " - Splitting continues until nodes\n",
    "   - contain a minimum number of training examples\n",
    "   - max tree depth is reached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other points\n",
    "- Decision Tree has another name: Classification and Regression Tree (CART) - introduced by Leo Breiman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going deeper: Creation of DT\n",
    "1. Gini Index\n",
    "2. Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini Index\n",
    "- Cost function to evaluate splits\n",
    "- What is the split?\n",
    " - Each split involves one input attribute and one value in that attribute\n",
    " - Each split can be used to divide training data into two groups of rows\n",
    "- Gini score tells us how good a split is. How?\n",
    " - __BY HOW MIXED THE CLASSES ARE IN THE TWO GROUPS CREATED BY THE SPLIT__\n",
    " - i.e. a perfect separation will produce Gini score of 0\n",
    " - worse case split (50/50 classes in each group) will produce Gini score of 0.5 (for 2 class problem)\n",
    " \n",
    " https://www.kdnuggets.com/2020/02/decision-tree-intuition.html\n",
    " \n",
    "### How to calculate?\n",
    "- imagine that the dataset has been split, so we have multiple nodes / groups of data\n",
    "- calculate the __proportion__ of classes in each group\n",
    "- Using the __Gini formula__, calculate Gini index\n",
    " - Gini index for __each group__ is weighed by the size of the group relative to all the samples in the parent (all samples currently being grouped.\n",
    " - Scores are __added__ across each child node at the split point to give a final Gini score for the split point that can be compared to other candidate split points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Gini index for a split dataset\n",
    "def gini_index(groups, classes):\n",
    "\t# count all samples at split point\n",
    "\tn_instances = float(sum([len(group) for group in groups]))\n",
    "\t# sum weighted Gini index for each group\n",
    "\tgini = 0.0\n",
    "\tfor group in groups:\n",
    "\t\tsize = float(len(group))\n",
    "\t\t# avoid divide by zero\n",
    "\t\tif size == 0:\n",
    "\t\t\tcontinue\n",
    "\t\tscore = 0.0\n",
    "\t\t# score the group based on the score for each class\n",
    "\t\tfor class_val in classes:\n",
    "\t\t\tp = [row[-1] for row in group].count(class_val) / size\n",
    "\t\t\tscore += p * p\n",
    "\t\t# weight the group score by its relative size\n",
    "\t\tgini += (1.0 - score) * (size / n_instances)\n",
    "\treturn gini\n",
    "# Learn list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# test Gini values\n",
    "print(gini_index([[[1, 1], [1, 1]], [[1, 1], [0, 0]]], [0, 0]))\n",
    "print(gini_index([[[1, 0], [1, 0]], [[1, 0], [1, 0]]], [0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Interview Questions\n",
    "- What are the decision trees? üë∂\n",
    "- How do we train decision trees? üë©‚Äçüéì\n",
    "- What are the main parameters of the decision tree model? üë∂\n",
    "- How do we handle categorical variables in decision trees? üë©‚Äçüéì\n",
    "- What are the benefits of a single decision tree compared to more complex models? üë©‚Äçüéì\n",
    "- How can we know which features are more important for the decision tree model? üë©‚Äçüéì"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/\n",
    "\n",
    "Showing picture in Jupyter Notebook\n",
    "- https://stackoverflow.com/questions/32370281/how-to-embed-image-or-picture-in-jupyter-notebook-either-from-a-local-machine-o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
