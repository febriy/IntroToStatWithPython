{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "### Introduction: Motivation for DT\n",
    "- Simple and effective model for classification and regression problem.\n",
    "- Easy to understand, mimic human decision making.\n",
    "- Foundation to more advanced ensemble methods e.g. bagging, random forests, gradient boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does it look like?\n",
    "- Represented by a binary tree \n",
    " - each node can have 0,1,2 child nodes\n",
    " - A node represent a split point on that variable\n",
    " - The leaf/ terminal nodes are used to make prediction\n",
    " - Once created, we can imagine new data to be predicted traversing throughout the tree through the branches to the leaf node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Yaktocat](https://upload.wikimedia.org/wikipedia/commons/4/46/ID3_algorithm_decision_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create the tree?\n",
    "- Simply said, it is a process of dividing up the input space\n",
    "- Recursive binary splitting - a greedy approach used to divide the space. How does it work?\n",
    " - Line up all values \n",
    " - Try different split points\n",
    " - Test using a cost function\n",
    " - Choose the split with the lowest cost\n",
    "   - __Regression__ : sum squared error\n",
    "   - __Classification__ : Gini cost\n",
    " - Splitting continues until nodes\n",
    "   - contain a minimum number of training examples\n",
    "   - max tree depth is reached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other points\n",
    "- Decision Tree has another name: Classification and Regression Tree (CART) - introduced by Leo Breiman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going deeper: Creation of DT\n",
    "1. Gini Index\n",
    "2. Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini Index\n",
    "### Introduction\n",
    "- Cost function to evaluate splits\n",
    "- What is the split?\n",
    " - Each split involves one input attribute and one value in that attribute\n",
    " - Each split can be used to divide training data into two groups of rows\n",
    "- Gini score tells us how good a split is. How?\n",
    " - __BY HOW MIXED THE CLASSES ARE IN THE TWO GROUPS CREATED BY THE SPLIT__\n",
    " - i.e. a perfect separation will produce Gini score of 0\n",
    " - worse case split (50/50 classes in each group) will produce Gini score of 0.5 (for 2 class problem)\n",
    " \n",
    " https://www.kdnuggets.com/2020/02/decision-tree-intuition.html\n",
    " \n",
    "### How to calculate?\n",
    "- imagine that the dataset has been split, so we have multiple nodes / groups of data\n",
    "- calculate the __proportion__ of classes in each group\n",
    "- Using the __Gini formula__, calculate Gini index\n",
    " - Gini index for __each group__ is weighed by the size of the group relative to all the samples in the parent (all samples currently being grouped.\n",
    " - Scores are __added__ across each child node at the split point to give a final Gini score for the split point that can be compared to other candidate split points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Yaktocat](https://miro.medium.com/max/548/1*FgY28bBeLYG9Zg4_q4LxTA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Gini index for a split dataset\n",
    "def gini_index(groups, classes):\n",
    "\t# count all samples at split point (get total no.of samples)\n",
    "\tn_instances = float(sum([len(group) for group in groups]))\n",
    "\t# sum weighted Gini index for each group\n",
    "\tgini = 0.0\n",
    "\tfor group in groups:\n",
    "\t\tsize = float(len(group))\n",
    "\t\t# avoid divide by zero\n",
    "\t\tif size == 0:\n",
    "\t\t\tcontinue\n",
    "\t\tscore = 0.0\n",
    "\t\t# score the group based on the score for each class\n",
    "\t\tfor class_val in classes:\n",
    "\t\t\tp = [row[-1] for row in group].count(class_val) / size\n",
    "\t\t\tscore += p * p\n",
    "\t\t# weight the group score by its relative size\n",
    "\t\tgini += (1.0 - score) * (size / n_instances)\n",
    "\treturn gini\n",
    "# Learn list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# test Gini values\n",
    "print(gini_index([[[1, 1], [1, 1]], [[1, 1], [0, 0]]], [0, 0]))\n",
    "\n",
    "print(gini_index([[[1, 0], [1, 0]], \n",
    "                  [[1, 0], [1, 0]]],\n",
    "                  [0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best split can be determined by one that gives the best Gini score.\n",
    "\n",
    "## Create Split\n",
    "- Split is made up of an attribute and a value\n",
    "- We will create splits and evaluate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(index, value, dataset):\n",
    "\tleft, right = list(), list()\n",
    "\tfor row in dataset:\n",
    "\t\tif row[index] < value:\n",
    "\t\t\tleft.append(row)\n",
    "\t\telse:\n",
    "\t\t\tright.append(row)\n",
    "\treturn left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate split\n",
    "- Check every value on each attribute as a candidate split\n",
    "- Evaluate cost of the split to find best possible split\n",
    "- This is an exhaustive and greedy algorithm\n",
    "\n",
    "#### Explaining the code below\n",
    "- dictionary to represent node\n",
    "- store attribute index, value, the 2 groups of split data\n",
    "- the 2 groups will be split again recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best split point for a dataset\n",
    "def get_split(dataset):\n",
    "\tclass_values = list(set(row[-1] for row in dataset))\n",
    "\tb_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "\tfor index in range(len(dataset[0])-1):\n",
    "\t\tfor row in dataset:\n",
    "\t\t\tgroups = test_split(index, row[index], dataset)\n",
    "\t\t\tgini = gini_index(groups, class_values)\n",
    "\t\t\tif gini < b_score:\n",
    "\t\t\t\tb_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "\treturn {'index':b_index, 'value':b_value, 'groups':b_groups}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 < 2.771 Gini=0.444\n",
      "X1 < 1.729 Gini=0.500\n",
      "X1 < 3.678 Gini=0.286\n",
      "X1 < 3.961 Gini=0.167\n",
      "X1 < 2.999 Gini=0.375\n",
      "X1 < 7.498 Gini=0.286\n",
      "X1 < 9.002 Gini=0.375\n",
      "X1 < 7.445 Gini=0.167\n",
      "X1 < 10.125 Gini=0.444\n",
      "X1 < 6.642 Gini=0.000\n",
      "X2 < 1.785 Gini=0.500\n",
      "X2 < 1.170 Gini=0.444\n",
      "X2 < 2.813 Gini=0.320\n",
      "X2 < 2.620 Gini=0.417\n",
      "X2 < 2.209 Gini=0.476\n",
      "X2 < 3.163 Gini=0.167\n",
      "X2 < 3.339 Gini=0.444\n",
      "X2 < 0.477 Gini=0.500\n",
      "X2 < 3.235 Gini=0.286\n",
      "X2 < 3.320 Gini=0.375\n",
      "Split: [X1 < 6.642]\n"
     ]
    }
   ],
   "source": [
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(index, value, dataset):\n",
    "\tleft, right = list(), list()\n",
    "\tfor row in dataset:\n",
    "\t\tif row[index] < value:\n",
    "\t\t\tleft.append(row)\n",
    "\t\telse:\n",
    "\t\t\tright.append(row)\n",
    "\treturn left, right\n",
    "\n",
    "# Calculate the Gini index for a split dataset\n",
    "def gini_index(groups, classes):\n",
    "\t# count all samples at split point\n",
    "\tn_instances = float(sum([len(group) for group in groups]))\n",
    "\t# sum weighted Gini index for each group\n",
    "\tgini = 0.0\n",
    "\tfor group in groups:\n",
    "\t\tsize = float(len(group))\n",
    "\t\t# avoid divide by zero\n",
    "\t\tif size == 0:\n",
    "\t\t\tcontinue\n",
    "\t\tscore = 0.0\n",
    "\t\t# score the group based on the score for each class\n",
    "\t\tfor class_val in classes:\n",
    "\t\t\tp = [row[-1] for row in group].count(class_val) / size\n",
    "\t\t\tscore += p * p\n",
    "\t\t# weight the group score by its relative size\n",
    "\t\tgini += (1.0 - score) * (size / n_instances)\n",
    "\treturn gini\n",
    "\n",
    "# Select the best split point for a dataset\n",
    "def get_split(dataset):\n",
    "\tclass_values = list(set(row[-1] for row in dataset))\n",
    "\tb_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "\tfor index in range(len(dataset[0])-1):\n",
    "\t\tfor row in dataset:\n",
    "\t\t\tgroups = test_split(index, row[index], dataset)\n",
    "\t\t\tgini = gini_index(groups, class_values)\n",
    "\t\t\tprint('X%d < %.3f Gini=%.3f' % ((index+1), row[index], gini))\n",
    "\t\t\tif gini < b_score:\n",
    "\t\t\t\tb_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "\treturn {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "\n",
    "dataset = [[2.771244718,1.784783929,0],\n",
    "\t[1.728571309,1.169761413,0],\n",
    "\t[3.678319846,2.81281357,0],\n",
    "\t[3.961043357,2.61995032,0],\n",
    "\t[2.999208922,2.209014212,0],\n",
    "\t[7.497545867,3.162953546,1],\n",
    "\t[9.00220326,3.339047188,1],\n",
    "\t[7.444542326,0.476683375,1],\n",
    "\t[10.12493903,3.234550982,1],\n",
    "\t[6.642287351,3.319983761,1]]\n",
    "split = get_split(dataset)\n",
    "print('Split: [X%d < %.3f]' % ((split['index']+1), split['value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a tree\n",
    "3 steps:\n",
    "1. Terminal Nodes\n",
    "2. Recursive Splitting\n",
    "3. Building a Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminal Nodes\n",
    "We can determine hyperparameters to decide when to stop the tree:\n",
    "1. Maximum Tree Depth - max no. of nodes from the root node of the tree\n",
    "2. Minimum Node Records - min no. of training patters a given node is responsible for\n",
    "\n",
    "Decision tree final decision is made by traversing the tree from the root to the terminal node and selecting the most common class in the terminal node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a terminal node value\n",
    "def to_terminal(group):\n",
    "\toutcomes = [row[-1] for row in group]\n",
    "\treturn max(set(outcomes), key=outcomes.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Splitting\n",
    "- Call get_split() function over and over again.\n",
    "- Child node split recursively.\n",
    "\n",
    "#### Explaining the function below\n",
    "1. Two groups of data split by the node are extracted for use and deleted from the node as we no longer require access to these data.\n",
    "2. Check if either left or right group of rows is empty. If so, create terminal node. \n",
    "3. Check if we have reached maximum depth.\n",
    "4. We then process the left child (greedy!).\n",
    " - Create terminal node is the group of rows is too small.\n",
    " - Otherwise, create and add the left node in a depth first. fashion until the bottom of the tree is reaches on this branch.\n",
    "5. Then, process the right side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create child splits for a node or make terminal\n",
    "def split(node, max_depth, min_size, depth):\n",
    "\tleft, right = node['groups']\n",
    "\tdel(node['groups'])\n",
    "\t# check for a no split\n",
    "\tif not left or not right:\n",
    "\t\tnode['left'] = node['right'] = to_terminal(left + right)\n",
    "\t\treturn\n",
    "\t# check for max depth\n",
    "\tif depth >= max_depth:\n",
    "\t\tnode['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "\t\treturn\n",
    "\t# process left child\n",
    "\tif len(left) <= min_size:\n",
    "\t\tnode['left'] = to_terminal(left)\n",
    "\telse:\n",
    "\t\tnode['left'] = get_split(left)\n",
    "\t\tsplit(node['left'], max_depth, min_size, depth+1)\n",
    "\t# process right child\n",
    "\tif len(right) <= min_size:\n",
    "\t\tnode['right'] = to_terminal(right)\n",
    "\telse:\n",
    "\t\tnode['right'] = get_split(right)\n",
    "\t\tsplit(node['right'], max_depth, min_size, depth+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Tree\n",
    "- Create root node\n",
    "- Call split() function recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "\troot = get_split(train)\n",
    "\tsplit(root, max_depth, min_size, 1)\n",
    "\treturn root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X1 < 6.642]\n",
      " [0]\n",
      " [1]\n"
     ]
    }
   ],
   "source": [
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(index, value, dataset):\n",
    "\tleft, right = list(), list()\n",
    "\tfor row in dataset:\n",
    "\t\tif row[index] < value:\n",
    "\t\t\tleft.append(row)\n",
    "\t\telse:\n",
    "\t\t\tright.append(row)\n",
    "\treturn left, right\n",
    "\n",
    "# Calculate the Gini index for a split dataset\n",
    "def gini_index(groups, classes):\n",
    "\t# count all samples at split point\n",
    "\tn_instances = float(sum([len(group) for group in groups]))\n",
    "\t# sum weighted Gini index for each group\n",
    "\tgini = 0.0\n",
    "\tfor group in groups:\n",
    "\t\tsize = float(len(group))\n",
    "\t\t# avoid divide by zero\n",
    "\t\tif size == 0:\n",
    "\t\t\tcontinue\n",
    "\t\tscore = 0.0\n",
    "\t\t# score the group based on the score for each class\n",
    "\t\tfor class_val in classes:\n",
    "\t\t\tp = [row[-1] for row in group].count(class_val) / size\n",
    "\t\t\tscore += p * p\n",
    "\t\t# weight the group score by its relative size\n",
    "\t\tgini += (1.0 - score) * (size / n_instances)\n",
    "\treturn gini\n",
    "\n",
    "# Select the best split point for a dataset\n",
    "def get_split(dataset):\n",
    "\tclass_values = list(set(row[-1] for row in dataset))\n",
    "\tb_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "\tfor index in range(len(dataset[0])-1):\n",
    "\t\tfor row in dataset:\n",
    "\t\t\tgroups = test_split(index, row[index], dataset)\n",
    "\t\t\tgini = gini_index(groups, class_values)\n",
    "\t\t\tif gini < b_score:\n",
    "\t\t\t\tb_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "\treturn {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "\n",
    "# Create a terminal node value\n",
    "def to_terminal(group):\n",
    "\toutcomes = [row[-1] for row in group]\n",
    "\treturn max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "# Create child splits for a node or make terminal\n",
    "def split(node, max_depth, min_size, depth):\n",
    "\tleft, right = node['groups']\n",
    "\tdel(node['groups'])\n",
    "\t# check for a no split\n",
    "\tif not left or not right:\n",
    "\t\tnode['left'] = node['right'] = to_terminal(left + right)\n",
    "\t\treturn\n",
    "\t# check for max depth\n",
    "\tif depth >= max_depth:\n",
    "\t\tnode['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "\t\treturn\n",
    "\t# process left child\n",
    "\tif len(left) <= min_size:\n",
    "\t\tnode['left'] = to_terminal(left)\n",
    "\telse:\n",
    "\t\tnode['left'] = get_split(left)\n",
    "\t\tsplit(node['left'], max_depth, min_size, depth+1)\n",
    "\t# process right child\n",
    "\tif len(right) <= min_size:\n",
    "\t\tnode['right'] = to_terminal(right)\n",
    "\telse:\n",
    "\t\tnode['right'] = get_split(right)\n",
    "\t\tsplit(node['right'], max_depth, min_size, depth+1)\n",
    "\n",
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "\troot = get_split(train)\n",
    "\tsplit(root, max_depth, min_size, 1)\n",
    "\treturn root\n",
    "\n",
    "# Print a decision tree\n",
    "def print_tree(node, depth=0):\n",
    "\tif isinstance(node, dict):\n",
    "\t\tprint('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
    "\t\tprint_tree(node['left'], depth+1)\n",
    "\t\tprint_tree(node['right'], depth+1)\n",
    "\telse:\n",
    "\t\tprint('%s[%s]' % ((depth*' ', node)))\n",
    "\n",
    "dataset = [[2.771244718,1.784783929,0],\n",
    "\t[1.728571309,1.169761413,0],\n",
    "\t[3.678319846,2.81281357,0],\n",
    "\t[3.961043357,2.61995032,0],\n",
    "\t[2.999208922,2.209014212,0],\n",
    "\t[7.497545867,3.162953546,1],\n",
    "\t[9.00220326,3.339047188,1],\n",
    "\t[7.444542326,0.476683375,1],\n",
    "\t[10.12493903,3.234550982,1],\n",
    "\t[6.642287351,3.319983761,1]]\n",
    "tree = build_tree(dataset, 1, 1)\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the max depth parameter!\n",
    "Realise that there are points when hyperparameter need to be tuned according to the problem.\n",
    "\n",
    "Now we know how to train a tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "\tif row[node['index']] < node['value']:\n",
    "\t\tif isinstance(node['left'], dict):\n",
    "\t\t\treturn predict(node['left'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['left']\n",
    "\telse:\n",
    "\t\tif isinstance(node['right'], dict):\n",
    "\t\t\treturn predict(node['right'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected=0, Got=0\n",
      "Expected=0, Got=0\n",
      "Expected=0, Got=0\n",
      "Expected=0, Got=0\n",
      "Expected=0, Got=0\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "\tif row[node['index']] < node['value']:\n",
    "\t\tif isinstance(node['left'], dict):\n",
    "\t\t\treturn predict(node['left'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['left']\n",
    "\telse:\n",
    "\t\tif isinstance(node['right'], dict):\n",
    "\t\t\treturn predict(node['right'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['right']\n",
    "\n",
    "dataset = [[2.771244718,1.784783929,0],\n",
    "\t[1.728571309,1.169761413,0],\n",
    "\t[3.678319846,2.81281357,0],\n",
    "\t[3.961043357,2.61995032,0],\n",
    "\t[2.999208922,2.209014212,0],\n",
    "\t[7.497545867,3.162953546,1],\n",
    "\t[9.00220326,3.339047188,1],\n",
    "\t[7.444542326,0.476683375,1],\n",
    "\t[10.12493903,3.234550982,1],\n",
    "\t[6.642287351,3.319983761,1]]\n",
    "\n",
    "#  predict with a stump\n",
    "stump = {'index': 0, 'right': 1, 'value': 6.642287351, 'left': 0}\n",
    "for row in dataset:\n",
    "\tprediction = predict(stump, row)\n",
    "\tprint('Expected=%d, Got=%d' % (row[-1], prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Banknote Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [96.35036496350365, 97.08029197080292, 97.44525547445255, 98.17518248175182, 97.44525547445255]\n",
      "Mean Accuracy: 97.299%\n"
     ]
    }
   ],
   "source": [
    "# CART on the Bank Note dataset\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "\n",
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "\tfile = open(filename, \"rt\")\n",
    "\tlines = reader(file)\n",
    "\tdataset = list(lines)\n",
    "\treturn dataset\n",
    "\n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = float(row[column].strip())\n",
    "\n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "\tdataset_split = list()\n",
    "\tdataset_copy = list(dataset)\n",
    "\tfold_size = int(len(dataset) / n_folds)\n",
    "\tfor i in range(n_folds):\n",
    "\t\tfold = list()\n",
    "\t\twhile len(fold) < fold_size:\n",
    "\t\t\tindex = randrange(len(dataset_copy))\n",
    "\t\t\tfold.append(dataset_copy.pop(index))\n",
    "\t\tdataset_split.append(fold)\n",
    "\treturn dataset_split\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "\tcorrect = 0\n",
    "\tfor i in range(len(actual)):\n",
    "\t\tif actual[i] == predicted[i]:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn correct / float(len(actual)) * 100.0\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "\tfolds = cross_validation_split(dataset, n_folds)\n",
    "\tscores = list()\n",
    "\tfor fold in folds:\n",
    "\t\ttrain_set = list(folds)\n",
    "\t\ttrain_set.remove(fold)\n",
    "\t\ttrain_set = sum(train_set, [])\n",
    "\t\ttest_set = list()\n",
    "\t\tfor row in fold:\n",
    "\t\t\trow_copy = list(row)\n",
    "\t\t\ttest_set.append(row_copy)\n",
    "\t\t\trow_copy[-1] = None\n",
    "\t\tpredicted = algorithm(train_set, test_set, *args)\n",
    "\t\tactual = [row[-1] for row in fold]\n",
    "\t\taccuracy = accuracy_metric(actual, predicted)\n",
    "\t\tscores.append(accuracy)\n",
    "\treturn scores\n",
    "\n",
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(index, value, dataset):\n",
    "\tleft, right = list(), list()\n",
    "\tfor row in dataset:\n",
    "\t\tif row[index] < value:\n",
    "\t\t\tleft.append(row)\n",
    "\t\telse:\n",
    "\t\t\tright.append(row)\n",
    "\treturn left, right\n",
    "\n",
    "# Calculate the Gini index for a split dataset\n",
    "def gini_index(groups, classes):\n",
    "\t# count all samples at split point\n",
    "\tn_instances = float(sum([len(group) for group in groups]))\n",
    "\t# sum weighted Gini index for each group\n",
    "\tgini = 0.0\n",
    "\tfor group in groups:\n",
    "\t\tsize = float(len(group))\n",
    "\t\t# avoid divide by zero\n",
    "\t\tif size == 0:\n",
    "\t\t\tcontinue\n",
    "\t\tscore = 0.0\n",
    "\t\t# score the group based on the score for each class\n",
    "\t\tfor class_val in classes:\n",
    "\t\t\tp = [row[-1] for row in group].count(class_val) / size\n",
    "\t\t\tscore += p * p\n",
    "\t\t# weight the group score by its relative size\n",
    "\t\tgini += (1.0 - score) * (size / n_instances)\n",
    "\treturn gini\n",
    "\n",
    "# Select the best split point for a dataset\n",
    "def get_split(dataset):\n",
    "\tclass_values = list(set(row[-1] for row in dataset))\n",
    "\tb_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "\tfor index in range(len(dataset[0])-1):\n",
    "\t\tfor row in dataset:\n",
    "\t\t\tgroups = test_split(index, row[index], dataset)\n",
    "\t\t\tgini = gini_index(groups, class_values)\n",
    "\t\t\tif gini < b_score:\n",
    "\t\t\t\tb_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "\treturn {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "\n",
    "# Create a terminal node value\n",
    "def to_terminal(group):\n",
    "\toutcomes = [row[-1] for row in group]\n",
    "\treturn max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "# Create child splits for a node or make terminal\n",
    "def split(node, max_depth, min_size, depth):\n",
    "\tleft, right = node['groups']\n",
    "\tdel(node['groups'])\n",
    "\t# check for a no split\n",
    "\tif not left or not right:\n",
    "\t\tnode['left'] = node['right'] = to_terminal(left + right)\n",
    "\t\treturn\n",
    "\t# check for max depth\n",
    "\tif depth >= max_depth:\n",
    "\t\tnode['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "\t\treturn\n",
    "\t# process left child\n",
    "\tif len(left) <= min_size:\n",
    "\t\tnode['left'] = to_terminal(left)\n",
    "\telse:\n",
    "\t\tnode['left'] = get_split(left)\n",
    "\t\tsplit(node['left'], max_depth, min_size, depth+1)\n",
    "\t# process right child\n",
    "\tif len(right) <= min_size:\n",
    "\t\tnode['right'] = to_terminal(right)\n",
    "\telse:\n",
    "\t\tnode['right'] = get_split(right)\n",
    "\t\tsplit(node['right'], max_depth, min_size, depth+1)\n",
    "\n",
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "\troot = get_split(train)\n",
    "\tsplit(root, max_depth, min_size, 1)\n",
    "\treturn root\n",
    "\n",
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "\tif row[node['index']] < node['value']:\n",
    "\t\tif isinstance(node['left'], dict):\n",
    "\t\t\treturn predict(node['left'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['left']\n",
    "\telse:\n",
    "\t\tif isinstance(node['right'], dict):\n",
    "\t\t\treturn predict(node['right'], row)\n",
    "\t\telse:\n",
    "\t\t\treturn node['right']\n",
    "\n",
    "# Classification and Regression Tree Algorithm\n",
    "def decision_tree(train, test, max_depth, min_size):\n",
    "\ttree = build_tree(train, max_depth, min_size)\n",
    "\tpredictions = list()\n",
    "\tfor row in test:\n",
    "\t\tprediction = predict(tree, row)\n",
    "\t\tpredictions.append(prediction)\n",
    "\treturn(predictions)\n",
    "\n",
    "# Test CART on Bank Note dataset\n",
    "seed(1)\n",
    "# load and prepare data\n",
    "filename = '/Users/admin/Documents/arvincodes/IntroToStatWithPython/dataset/data_banknote_authentication.csv'\n",
    "dataset = load_csv(filename)\n",
    "# convert string attributes to integers\n",
    "for i in range(len(dataset[0])):\n",
    "\tstr_column_to_float(dataset, i)\n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "max_depth = 5\n",
    "min_size = 10\n",
    "scores = evaluate_algorithm(dataset, decision_tree, n_folds, max_depth, min_size)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Interview Questions\n",
    "- What are the decision trees? 👶\n",
    " - Classification and Regression Tree, used to make prediction based on certain patterns seen in a training dataset\n",
    " - Mimic human decision making process\n",
    " - Traverse the tree to the terminal node and use the most common value in the node to determine predicted class (for classification problem)\n",
    "- How do we train decision trees? 👩‍🎓\n",
    " - Find best split recursively until terminal node condition is fulfilled (pure tree, max depth hit, min sample hit)\n",
    "- What are the main parameters of the decision tree model? 👶\n",
    " - max depth\n",
    " - min sample in node\n",
    "- How do we handle categorical variables in decision trees? 👩‍🎓\n",
    " - label them\n",
    "- What are the benefits of a single decision tree compared to more complex models? 👩‍🎓\n",
    " - Simple to train\n",
    " - Potentially lower computational resources\n",
    " - Might work better when groups are more obvious/ simpler dataset\n",
    " - More explainable\n",
    "- How can we know which features are more important for the decision tree model? 👩‍🎓\n",
    " - Analyse the dataset e.g. how many groups are there in the classification problem, how complicated does a plot look like \n",
    " - Experiment with hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo\n",
    "- Create practice notebook on list comprehension\n",
    "- Clarify understanding on the Gini score\n",
    "- Re-read the notebook, rewriting them as you gain better understanding. \n",
    " - Remember, the decision tree algorithm is actually very easy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/\n",
    "- https://towardsdatascience.com/decision-tree-from-scratch-in-python-46e99dfea775\n",
    "\n",
    "Showing picture in Jupyter Notebook\n",
    "- https://stackoverflow.com/questions/32370281/how-to-embed-image-or-picture-in-jupyter-notebook-either-from-a-local-machine-o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
